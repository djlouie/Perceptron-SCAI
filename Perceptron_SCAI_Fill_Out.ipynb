{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39RGliZHerG3"
   },
   "source": [
    "# Perceptron Notebook!\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/djlouie/Perceptron-SCAI/blob/main/Perceptron_SCAI_Fill_Out.ipynb\">\n",
    "\t<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "or7xlbIwecEc"
   },
   "source": [
    "## 1.  Perceptron / McCulloch-Pitts Neuron\n",
    "\n",
    "$$\\hat{y}(x) = H(\\sum_{i=1}^{n}w_ix_i)$$\n",
    "\n",
    "or\n",
    "\n",
    "$$\\hat{y}(x) = H(w \\cdot x)$$\n",
    "\n",
    "or\n",
    "\n",
    "$$\\hat{y}(x) = H(w^Tx)$$\n",
    "\n",
    "where $H$ is the heaviside step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vHehb0l6vGbr"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NpAFnxx6egGV"
   },
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "\tdef __init__(self, w, b):\n",
    "\t\tself.w = w\n",
    "\t\tself.b = b\n",
    "\n",
    "\tdef predict(self, x: Tensor):\n",
    "\t\t\n",
    "\t\t################################\n",
    "\t\t# Fill Out Prediction Function #\n",
    "\t\t################################\n",
    "\t\t\n",
    "\t\treturn None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvYYW6Zzex7F"
   },
   "source": [
    "## 2. Let's Test Our Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u9Tjcmy0e1g9",
    "outputId": "d149b850-560c-4f4e-892d-ceb94100ab0d"
   },
   "outputs": [],
   "source": [
    "# create an instance of the perceptron with weights (1, -1) and bias 0\n",
    "q1 = Perceptron(torch.tensor([1.0, -1.0]), 0)\n",
    "x = torch.tensor([0.5, 0.8])\n",
    "y_hat = q1.predict(x)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z0WorpAHe2fZ",
    "outputId": "ded3d961-6b6a-443c-ba68-e9ea882fd8ea"
   },
   "outputs": [],
   "source": [
    "# instance of the perceptron with weights (0.2, 0.75, -0.5) and bias -3\n",
    "q2 = Perceptron(torch.tensor([0.2, 0.75, -0.5]), -3)\n",
    "x = torch.tensor([10.0, 20.0, 30.0])\n",
    "y_hat = q2.predict(x)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qOIz8cjYe32k",
    "outputId": "6bc8b8b1-f0d8-43ce-f9f3-e23884ee3169"
   },
   "outputs": [],
   "source": [
    "# instance of the perceptron with weights (-2, -2) and bias 3\n",
    "q3456 = Perceptron(torch.tensor([-2, -2]), 3)\n",
    "\n",
    "x_hist = []\n",
    "y_hats = []\n",
    "for i in range(2):\n",
    "\tfor j in range(2):\n",
    "\t\tx = torch.tensor([i, j])\n",
    "\t\tx_hist.append(x)\n",
    "\t\ty_hats.append(q3456.predict(x))\n",
    "\n",
    "print(x_hist)\n",
    "print(y_hats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ms0T3AJzfe4x"
   },
   "source": [
    "## 3. Perceptron Learning Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yy16PkQ3fiGs"
   },
   "source": [
    "#### 3.1 Plotting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KIU-4uW0fY9M"
   },
   "outputs": [],
   "source": [
    "def plot_perceptron(neuron, max_x, min_x, x_coords_0, y_coords_0, x_coords_1, y_coords_1):\n",
    "\t\t# Create the plot\n",
    "\t\tplt.scatter(x_coords_0, y_coords_0, c='red', label='Class 0')\n",
    "\t\tplt.scatter(x_coords_1, y_coords_1, c='blue', label='Class 1')\n",
    "\n",
    "\t\t# Add titles and labels\n",
    "\t\tplt.title('Points')\n",
    "\t\tplt.xlabel('X-axis')\n",
    "\t\tplt.ylabel('Y-axis')\n",
    "\t\tplt.grid(True)  # Optional: add a grid\n",
    "\n",
    "\t\t# Plot Weight Vector\n",
    "\t\tplt.arrow(0,0,neuron.w[0], neuron.w[1], width=0.02, head_width=0.05)\n",
    "\n",
    "\t\t#Calculate the boundary line variables\n",
    "\t\tif neuron.w[0] != 0 and neuron.w[1] != 0:\n",
    "\t\t\tvector_slope = neuron.w[1]/neuron.w[0]\n",
    "\t\t\tbound_slope = -1/vector_slope\n",
    "\t\t\tx = np.linspace(min_x, max_x, num=1000)\n",
    "\t\t\ty = bound_slope * x\n",
    "\n",
    "\t\t\t#Plot the line\n",
    "\t\t\tplt.plot(x, y)\n",
    "\t\telif neuron.w[0] != 0 and neuron.w[1] == 0:\n",
    "\t\t\t#Plot the vertical line\n",
    "\t\t\tplt.axvline(x=0)\n",
    "\t\telif neuron.w[0] == 0 and neuron.w[1] != 0:\n",
    "\t\t\t#Plot the horizontal line\n",
    "\t\t\tplt.axhline(y=0)\n",
    "\n",
    "\t\t#Show the graph\n",
    "\t\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dUYTBFKfsax"
   },
   "source": [
    "### 3.2 Create Simplified Perceptron Class\n",
    "\n",
    "We will set bias to 0 for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BOiO4P51f0st"
   },
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "\tdef __init__(self,w):\n",
    "\t\tself.w = w\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tactivation = torch.dot(self.w,x)\n",
    "\t\treturn activation\n",
    "\n",
    "\tdef predict(self, x):\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\t\n",
    "\t\t\t################################\n",
    "\t\t\t# Fill Out Prediction Function #\n",
    "\t\t\t################################\n",
    "\n",
    "\t\t\treturn None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4DgkVGwof8Jm"
   },
   "source": [
    "### 3.3 Make Data For the Perceptron to Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qm6zM5dif5Vj"
   },
   "outputs": [],
   "source": [
    "#Data\n",
    "data=torch.tensor([(-1, -1), (-1, -0.5), (-1, 0), (-1, 0.5), (1, 0.5), (1, -0.5), (1, 1), (1, -1)],dtype=float)\n",
    "label=torch.tensor([1,1,1,1,0,0,0,0], dtype=float)\n",
    "\n",
    "min_x = min(data[:, 0])\n",
    "max_x = max(data[:, 0])\n",
    "\n",
    "data_size=len(data)\n",
    "data_sum=torch.sum(data,dim=0)\n",
    "data_mean=data_sum/data_size\n",
    "\n",
    "x_coords_0 = [point[0] for point, label in zip(data, label) if label == 0]\n",
    "y_coords_0 = [point[1] for point, label in zip(data, label) if label == 0]\n",
    "x_coords_1 = [point[0] for point, label in zip(data, label) if label == 1]\n",
    "y_coords_1 = [point[1] for point, label in zip(data, label) if label == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StUigcH3iJmW"
   },
   "source": [
    "### 3.4 Perceptron Learning with Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7lj2U12pggyw"
   },
   "outputs": [],
   "source": [
    "# Define a learning rate\n",
    "lr = 0.1\n",
    "# Define a loss function\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MblGnvTBgL55",
    "outputId": "75246331-b9f6-4317-8b04-fe21ec8741b2"
   },
   "outputs": [],
   "source": [
    "#Finding Weight\n",
    "weight = torch.tensor([random.random(), random.random()], requires_grad=True, dtype=float)\n",
    "learning_rate = 0.5\n",
    "neuron = Perceptron(weight)\n",
    "\n",
    "# Initial Plot\n",
    "if neuron != None:\n",
    "\tprint('Initial Plot')\n",
    "\twith torch.no_grad():\n",
    "\t\tprint(f\"{neuron.w.tolist()} - {learning_rate}*{neuron.w.grad}\")\n",
    "\t\tplot_perceptron(neuron, min_x, max_x, x_coords_0, y_coords_0, x_coords_1, y_coords_1)\n",
    "\n",
    "# Iterate Through Epochs\n",
    "for epoch in range(5):\n",
    "\told_w = neuron.w\n",
    "\tall_correct = True\n",
    "\t\n",
    "\t# Iterate Through Data\n",
    "\tfor i in range(len(data)):\n",
    "\t\tpoint = data[i]\n",
    "\t\ty = neuron.forward(point)\n",
    "\n",
    "\t\t# neuron update!\n",
    "\t\tloss_val = loss_fn(y, label[i])\n",
    "\n",
    "\t\t# Gradient calculation + weight update\n",
    "\t\tloss_val.backward()\n",
    "\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\t# store old w\n",
    "\t\t\told_w = neuron.w.detach().numpy().copy()\n",
    "\n",
    "\t\t\t# update w\n",
    "\t\t\tneuron.w -= lr * neuron.w.grad\n",
    "\n",
    "\t\t\t# Only Print Equation when prediction is wrong\n",
    "\t\t\tif label[i] != y_hat:\n",
    "\t\t\t\tprint(f\"{neuron.w.tolist()} - {learning_rate}*{neuron.w.grad}\")\n",
    "\n",
    "\t\t# Only Make a New Plot when the weights change\n",
    "\t\tif label[i] != y_hat:\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tplot_perceptron(neuron, max_x, min_x, x_coords_0, y_coords_0, x_coords_1, y_coords_1)\n",
    "\t\t\t\t\n",
    "\t\t# Break loop if perceptron predicts everything correct\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor i in range(len(data)):\n",
    "\t\t\t\tpoint = data[i]\n",
    "\t\t\t\ty_hat = neuron.predict(point)\n",
    "\t\t\t\tif y_hat != label[i]:\n",
    "\t\t\t\t\tall_correct = False\n",
    "\t\t\tif all_correct:\n",
    "\t\t\t\tbreak\n",
    "\tif all_correct:\n",
    "\t\tbreak"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
